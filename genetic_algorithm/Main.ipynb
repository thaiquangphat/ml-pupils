{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p_RfEwajKf0"
   },
   "source": [
    "# SETTING UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55372,
     "status": "ok",
     "timestamp": 1740835227497,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "F6tE9bowjJY3",
    "outputId": "44651f33-bd09-4f78-9a34-06bc7dc774a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1740835227805,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "PKFlAIf5iQIa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/content/drive/MyDrive/HCMUT/ML242/GA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740835227810,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "8WVwxoHxmUhq",
    "outputId": "8d0147fd-03b2-4b0a-b028-8b7913b66c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('/content/drive/MyDrive/HCMUT/ML242/GA'):\n",
    "    print(\"OK\")\n",
    "else: print(\"NO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qG5wv6ujk7Q"
   },
   "source": [
    "\n",
    "**Dataset structure**\n",
    "```\n",
    "dataset\n",
    "|-- Original\n",
    "|        |-- Training\n",
    "|        |       |-- glioma     (Tr_gl_xxxx.jpg)    --> 1321 images\n",
    "|        |       |-- meningioma (Tr_me_xxxx.jpg)    --> 1339 images\n",
    "|        |       |-- notumor    (Tr_no_xxxx.jpg)    --> 1595 images\n",
    "|        |       |-- pituitary  (Tr_pi_xxxx.jpg)    --> 1457 images\n",
    "|        |-- Testing\n",
    "|        |       |-- glioma     (Te_gl_xxxx.jpg)    --> 300 images\n",
    "|        |       |-- meningioma (Te_me_xxxx.jpg)    --> 306 images\n",
    "|        |       |-- notumor    (Te_no_xxxx.jpg)    --> 405 images\n",
    "|        |       |-- pituitary  (Te_pi_xxxx.jpg)    --> 300 images\n",
    "|-- AfterPreprocess\n",
    "|        |-- Training\n",
    "|        |       |-- glioma     (Tr_gl_xxxx.jpg)    --> 1321 images\n",
    "|        |       |-- meningioma (Tr_me_xxxx.jpg)    --> 1339 images\n",
    "|        |       |-- notumor    (Tr_no_xxxx.jpg)    --> 1595 images\n",
    "|        |       |-- pituitary  (Tr_pi_xxxx.jpg)    --> 1457 images\n",
    "|        |-- Testing\n",
    "|        |       |-- glioma     (Te_gl_xxxx.jpg)    --> 300 images\n",
    "|        |       |-- meningioma (Te_me_xxxx.jpg)    --> 306 images\n",
    "|        |       |-- notumor    (Te_no_xxxx.jpg)    --> 405 images\n",
    "|        |       |-- pituitary  (Te_pi_xxxx.jpg)    --> 300 images\n",
    "|        |-- augmented_img_paths.json\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0pEq30ymW0O"
   },
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XF8xm9Sjm659"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxXrU4oimWVt"
   },
   "outputs": [],
   "source": [
    "class ImgPreprocess:\n",
    "    def __init__ (self,\n",
    "                  origin_dir:str = \"dataset/Original\",\n",
    "                  save_dir:str = \"dataset/AfterPreprocess\"):\n",
    "        self.origin_dir = origin_dir\n",
    "        self.save_dir = save_dir\n",
    "        self.augmented_img_path = []\n",
    "\n",
    "    def crop_img(self, img, extra_padding:int=0):\n",
    "        \"\"\"\n",
    "\t        Finds the extreme points on the image and crops the rectangular out of them\n",
    "\t    \"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.erode(thresh, None, iterations=2)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "        extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "        extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "        extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "        new_img = img[extTop[1]-extra_padding:extBot[1]+extra_padding, extLeft[0]-extra_padding:extRight[0]+extra_padding].copy()\n",
    "\n",
    "        return new_img\n",
    "\n",
    "    def augment_img(self, img):\n",
    "        new_img = img.copy()\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            new_img = cv2.flip(new_img, 1)\n",
    "\n",
    "        angle = np.random.uniform(-30, 30)\n",
    "        (h, w) = new_img.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        new_img = cv2.warpAffine(new_img, M, (w, h),\n",
    "                                 flags=cv2.INTER_LINEAR,\n",
    "                                 borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "        alpha = np.random.uniform(0.8, 1.2)\n",
    "        beta = np.random.randint(-20, 20)\n",
    "        new_img = cv2.convertScaleAbs(new_img, alpha=alpha, beta=beta)\n",
    "\n",
    "        return new_img\n",
    "\n",
    "    def run_on_dataset(self, augment_ratio:float=0.25, final_size=(256, 256)):\n",
    "        sub_dirs = [\"Training\", \"Testing\"]\n",
    "        class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
    "        seed = 42\n",
    "\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        augmented_paths = {}\n",
    "\n",
    "        print(f\"----- Preprocessing -----\")\n",
    "\n",
    "        for dir in sub_dirs:\n",
    "            for name in class_names:\n",
    "                out_dir = os.path.join(self.save_dir, dir, name)\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        for dir in sub_dirs:\n",
    "            augmented_paths[dir] = {}\n",
    "            for name in class_names:\n",
    "                augmented_paths[dir][name] = []\n",
    "                in_dir = os.path.join(self.origin_dir, dir, name)\n",
    "                out_dir = os.path.join(self.save_dir, dir, name)\n",
    "\n",
    "                if not os.path.isdir(in_dir):\n",
    "                    print(f\"Bug found: in_dir not exist - in_dir: {in_dir}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Processing in {in_dir}\")\n",
    "\n",
    "                all_files = os.listdir(in_dir)\n",
    "                all_imgs = [img for img in all_files if img.lower().endswith(('.jpg'))]\n",
    "                if not all_imgs:\n",
    "                    continue\n",
    "\n",
    "                random.shuffle(all_imgs)\n",
    "                n_augment = int(len(all_imgs) * augment_ratio)\n",
    "                imgs_to_augment = set(all_files[:n_augment])\n",
    "                print(f\"--> Processing {len(all_imgs)} | Augmenting {n_augment} images.\")\n",
    "\n",
    "                rl_img = 0\n",
    "                rl_augment = 0\n",
    "                for img in all_imgs:\n",
    "                    in_path = os.path.join(in_dir, img)\n",
    "                    img_0 = cv2.imread(in_path)\n",
    "                    if img_0 is None:\n",
    "                        print(f\"Failed to read image: {in_path}\")\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        cropped_img = self.crop_img(img_0)\n",
    "                        rl_img += 1\n",
    "\n",
    "                        if img in imgs_to_augment:\n",
    "                            cropped_img = self.augment_img(cropped_img)\n",
    "                            augmented_paths[dir][name].append(os.path.join(out_dir, img))\n",
    "                            rl_augment += 1\n",
    "\n",
    "                        resized_img = cv2.resize(cropped_img, final_size, interpolation=cv2.INTER_AREA)\n",
    "                        out_path = os.path.join(out_dir, img)\n",
    "                        cv2.imwrite(out_path, resized_img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {in_path}: {e}\")\n",
    "\n",
    "                print(f\"----> Finish processing in {in_dir}\")\n",
    "                print(f\"----> Total preprocessed img: {rl_img} | Total augmented img: {rl_augment}\")\n",
    "\n",
    "        self.augmented_img_path = augmented_paths\n",
    "        augmented_json_file = \"augmented_img_paths.json\"\n",
    "        augmented_file_path = os.path.join(self.save_dir, augmented_json_file)\n",
    "        with open(augmented_file_path, 'w') as f:\n",
    "            json.dump(augmented_paths, f, indent=4)\n",
    "\n",
    "        print(f\"Preprocessing complete | Augmented image paths saved to {augmented_file_path}\")\n",
    "\n",
    "\n",
    "    def load_augmented_paths(self, json_filename:str=\"augmented_img_paths.json\"):\n",
    "        print(f\"----- Loading augmented images paths from json -----\")\n",
    "        file_path = os.path.join(self.save_dir, json_filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"JSON file not found: {file_path}\")\n",
    "            return None\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.augmented_img_path = data\n",
    "        print(f\"--> Loaded augmented image paths from {file_path} successfully\")\n",
    "        return data\n",
    "\n",
    "\n",
    "    def plot_single_img(self, img):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        if len(img.shape) == 2:\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321730,
     "status": "ok",
     "timestamp": 1740641075285,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "GbinYpmVKAdB",
    "outputId": "686ffee2-ca31-4437-afc7-a19219055f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Preprocessing -----\n",
      "Processing in dataset/Original/Training/glioma\n",
      "--> Processing 1321 | Augmenting 330 images.\n",
      "----> Finish processing in dataset/Original/Training/glioma\n",
      "----> Total preprocessed img: 1321 | Total augmented img: 330\n",
      "Processing in dataset/Original/Training/meningioma\n",
      "--> Processing 1339 | Augmenting 334 images.\n",
      "----> Finish processing in dataset/Original/Training/meningioma\n",
      "----> Total preprocessed img: 1339 | Total augmented img: 334\n",
      "Processing in dataset/Original/Training/notumor\n",
      "--> Processing 1595 | Augmenting 398 images.\n",
      "----> Finish processing in dataset/Original/Training/notumor\n",
      "----> Total preprocessed img: 1595 | Total augmented img: 398\n",
      "Processing in dataset/Original/Training/pituitary\n",
      "--> Processing 1457 | Augmenting 364 images.\n",
      "----> Finish processing in dataset/Original/Training/pituitary\n",
      "----> Total preprocessed img: 1457 | Total augmented img: 364\n",
      "Processing in dataset/Original/Testing/glioma\n",
      "--> Processing 300 | Augmenting 75 images.\n",
      "----> Finish processing in dataset/Original/Testing/glioma\n",
      "----> Total preprocessed img: 300 | Total augmented img: 75\n",
      "Processing in dataset/Original/Testing/meningioma\n",
      "--> Processing 306 | Augmenting 76 images.\n",
      "----> Finish processing in dataset/Original/Testing/meningioma\n",
      "----> Total preprocessed img: 306 | Total augmented img: 76\n",
      "Processing in dataset/Original/Testing/notumor\n",
      "--> Processing 405 | Augmenting 101 images.\n",
      "----> Finish processing in dataset/Original/Testing/notumor\n",
      "----> Total preprocessed img: 405 | Total augmented img: 101\n",
      "Processing in dataset/Original/Testing/pituitary\n",
      "--> Processing 300 | Augmenting 75 images.\n",
      "----> Finish processing in dataset/Original/Testing/pituitary\n",
      "----> Total preprocessed img: 300 | Total augmented img: 75\n",
      "Preprocessing complete | Augmented image paths saved to dataset/AfterPreprocess/augmented_img_paths.json\n"
     ]
    }
   ],
   "source": [
    "img_prep = ImgPreprocess()\n",
    "img_prep.run_on_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNxA3ONypLrB"
   },
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1740846223510,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "U3oWypSwpNXU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740846224358,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "xCjlHdgWpR-y"
   },
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__ (self, data_dir, class_names, transform=None, mode=\"Training\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.class_names = class_names\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_id, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(self.data_dir, self.mode, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.img_paths.append(img_path)\n",
    "                    self.labels.append(class_id)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype('float32') / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740846225825,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "C4tWdIv4r-ey"
   },
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(self,\n",
    "                 data_dir:str=\"dataset/AfterPreprocess\",\n",
    "                 batch_size=32,\n",
    "                 validation_split=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "        self.class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
    "\n",
    "\n",
    "    def get_dataloader(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "        full_train_set = BrainTumorDataset(data_dir=self.data_dir,\n",
    "                                           class_names=self.class_names,\n",
    "                                           transform=transform,\n",
    "                                           mode=\"Training\")\n",
    "\n",
    "        val_size = int(len(full_train_set) * self.validation_split)\n",
    "        train_size = len(full_train_set) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            full_train_set,\n",
    "            [train_size, val_size]\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=self.batch_size,\n",
    "                                shuffle=False)\n",
    "\n",
    "        test_dataset = BrainTumorDataset(data_dir=self.data_dir,\n",
    "                                         class_names=self.class_names,\n",
    "                                         transform=transform,\n",
    "                                         mode=\"Testing\")\n",
    "        test_loader = DataLoader(test_dataset,\n",
    "                                 batch_size=self.batch_size,\n",
    "                                 shuffle=False)\n",
    "        return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34538,
     "status": "ok",
     "timestamp": 1740834098595,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "2mTJRWDgu7_1",
    "outputId": "d31701cf-3880-49d7-a34c-e7d8e2ec13ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "loader = Loader(data_dir=\"dataset/AfterPreprocess\", batch_size=32, validation_split=0.2)\n",
    "train_loader, val_loader, test_loader = loader.get_dataloader()\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)  \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36652,
     "status": "ok",
     "timestamp": 1740834135245,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "nj4QlOKWuIkD",
    "outputId": "daa1572b-08a1-4af0-db8c-e59467a1de70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in val_loader:\n",
    "    print(images.shape) \n",
    "    print(labels.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8930,
     "status": "ok",
     "timestamp": 1740834144168,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "uYcuPAq3uMBP",
    "outputId": "afef6140-7056-4b49-e4f5-e7fd43a73a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTvB9d8_2PyD"
   },
   "source": [
    "# Dynamic Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740846239326,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "kiLIia7N3T9c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1740846258058,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "M4uSKMuC1FCj"
   },
   "outputs": [],
   "source": [
    "class DynamicNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_cnns=2,\n",
    "                 num_fcns=2,\n",
    "                 img_size=(1, 256, 256),\n",
    "                 filters=[32, 64],\n",
    "                 kernel_sizes=[3, 3],\n",
    "                 strides=[1, 1],\n",
    "                 pool_sizes=[2, 2],\n",
    "                 fcn_units=[128, 64],\n",
    "                 activation_index=0,\n",
    "                 lr=0.01):\n",
    "        super(DynamicNN, self).__init__()\n",
    "\n",
    "        self.num_cnns = num_cnns\n",
    "        self.num_fcns = num_fcns\n",
    "        self.img_size = img_size\n",
    "        self.filters = filters\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.strides = strides\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.fcn_units = fcn_units\n",
    "\n",
    "        self.activate_function_list = [nn.ReLU(), nn.Sigmoid(), nn.Tanh()]\n",
    "        self.activation_index = activation_index\n",
    "        self.activation_function = self.activate_function_list[self.activation_index]\n",
    "\n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        self.fc_layers = self._build_fc_layers()\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "    def _build_conv_layers(self):\n",
    "        layers = []\n",
    "        in_channels = self.img_size[0]\n",
    "\n",
    "        for i in range(self.num_cnns):\n",
    "            layers.append(nn.Conv2d(in_channels,\n",
    "                                    self.filters[i],\n",
    "                                    kernel_size=self.kernel_sizes[i],\n",
    "                                    stride=self.strides[i]))\n",
    "            layers.append(self.activation_function)\n",
    "            layers.append(nn.MaxPool2d(self.pool_sizes[i]))\n",
    "            in_channels = self.filters[i]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _build_fc_layers(self):\n",
    "        layers = []\n",
    "        H, W = self.img_size[1], self.img_size[2]\n",
    "        for i in range(self.num_cnns):\n",
    "            H = (H - self.kernel_sizes[i]) // self.strides[i] + 1\n",
    "            W = (W - self.kernel_sizes[i]) // self.strides[i] + 1\n",
    "            H = H // self.pool_sizes[i]\n",
    "            W = W // self.pool_sizes[i]\n",
    "\n",
    "        in_features = self.filters[-1] * H * W\n",
    "\n",
    "        for units in self.fcn_units:\n",
    "            layers.append(nn.Linear(in_features, units))\n",
    "            layers.append(self.activation_function)\n",
    "            in_features = units\n",
    "\n",
    "        layers.append(nn.Linear(self.fcn_units[-1], 4))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        info = \"DynamicNN Architecture:\\n\"\n",
    "        info += f\" Input Image Size: {self.img_size}\\n\"\n",
    "        info += f\" Number of CNN Layers: {self.num_cnns}\\n\"\n",
    "        for i in range(self.num_cnns):\n",
    "            in_channels = self.img_size[0] if i == 0 else self.filters[i-1]\n",
    "            info += f\"  CNN Layer {i+1}:\\n\"\n",
    "            info += f\"    Conv2d(in_channels={in_channels}, out_channels={self.filters[i]}, kernel_size={self.kernel_sizes[i]}, stride={self.strides[i]})\\n\"\n",
    "            info += f\"    MaxPool2d(pool_size={self.pool_sizes[i]})\\n\"\n",
    "        info += f\" Number of FCN Layers: {self.num_fcns}\\n\"\n",
    "        for i in range(self.num_fcns):\n",
    "            info += f\"  FCN Layer {i+1}: Linear(units={self.fcn_units[i]})\\n\"\n",
    "        info += f\" Final Classification Layer: Linear({self.fcn_units[-1]} -> 4) + Softmax\\n\"\n",
    "        info += f\" Activation Function: {self.activation_function.__class__.__name__}\\n\"\n",
    "        info += f\" Learning Rate: {self.lr}\\n\"\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1740846260693,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "jmv3-u4l-Y_O",
    "outputId": "b7b74313-c150-4d7e-b5f3-7ac9084f5d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicNN Architecture:\n",
      " Input Image Size: (1, 256, 256)\n",
      " Number of CNN Layers: 2\n",
      "  CNN Layer 1:\n",
      "    Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
      "    MaxPool2d(pool_size=2)\n",
      "  CNN Layer 2:\n",
      "    Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
      "    MaxPool2d(pool_size=2)\n",
      " Number of FCN Layers: 2\n",
      "  FCN Layer 1: Linear(units=128)\n",
      "  FCN Layer 2: Linear(units=64)\n",
      " Final Classification Layer: Linear(64 -> 4) + Softmax\n",
      " Activation Function: ReLU\n",
      " Learning Rate: 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_nn = DynamicNN()\n",
    "print(temp_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTXtcZv98l1B"
   },
   "source": [
    "# Genetic Algorithm Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740846261487,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "5bwOd4tC8pDZ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1740846265348,
     "user": {
      "displayName": "PHÚC HÀ NGUYỄN BẢO",
      "userId": "16633783422206702633"
     },
     "user_tz": -420
    },
    "id": "zJb1KPgx3MBV"
   },
   "outputs": [],
   "source": [
    "class GAOptimizer:\n",
    "    def __init__(self,\n",
    "                 population_size=10,\n",
    "                 generations=10,\n",
    "                 mutation_rate=0.1,\n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                 epochs_per_model=20,\n",
    "                 lr_choices=None,\n",
    "                 activation_functions=None,\n",
    "                 train_loader=None,\n",
    "                 val_loader=None,\n",
    "                 test_loader=None,\n",
    "                 criterion=None):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.device = device\n",
    "        print(f\"Training on {device}\")\n",
    "        self.epochs_per_model = epochs_per_model\n",
    "\n",
    "        if lr_choices is None:\n",
    "            self.lr_choices = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "        else:\n",
    "            self.lr_choices = lr_choices\n",
    "\n",
    "        if activation_functions is None:\n",
    "            self.activation_functions = [nn.ReLU(), nn.Sigmoid(), nn.Tanh()]\n",
    "        else:\n",
    "            self.activation_functions = activation_functions\n",
    "\n",
    "        self.population = []\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        if criterion is None:\n",
    "            self.criterion = nn.NLLLoss()\n",
    "        else:\n",
    "            self.criterion = criterion\n",
    "\n",
    "    def initialize_population(self,\n",
    "                              num_cnn_layers_range=(1, 4),\n",
    "                              num_fcn_layers_range=(1, 4)):\n",
    "        print(f\"Initialize population\")\n",
    "        for _ in range(self.population_size):\n",
    "            cnn_layers = random.randint(*num_cnn_layers_range)\n",
    "            fcn_layers = random.randint(*num_fcn_layers_range)\n",
    "            activation_index = random.randint(0, len(self.activation_functions) - 1)\n",
    "            lr = random.choice(self.lr_choices)\n",
    "\n",
    "            possible_filters = [16, 32, 64, 128]\n",
    "            filters = []\n",
    "            for i in range(cnn_layers):\n",
    "                if i == 0:\n",
    "                    filt = random.choice(possible_filters)\n",
    "                else:\n",
    "                    allowed = [f for f in possible_filters if f <= filters[i - 1]]\n",
    "                    filt = random.choice(allowed)\n",
    "                filters.append(filt)\n",
    "\n",
    "            allowed_kernel_sizes = [3, 5, 7]\n",
    "            kernel_sizes = []\n",
    "            for i in range(cnn_layers):\n",
    "                if i == 0:\n",
    "                    k = random.choice(allowed_kernel_sizes)\n",
    "                else:\n",
    "                    allowed = [ks for ks in allowed_kernel_sizes if ks <= kernel_sizes[i - 1]]\n",
    "                    k = random.choice(allowed)\n",
    "                kernel_sizes.append(k)\n",
    "\n",
    "            strides = [random.randint(1, 2) for _ in range(cnn_layers)]\n",
    "\n",
    "            allowed_pool_sizes = [2, 3, 4]\n",
    "            pool_sizes = []\n",
    "            for i in range(cnn_layers):\n",
    "                if i == 0:\n",
    "                    p = random.choice(allowed_pool_sizes)\n",
    "                else:\n",
    "                    allowed = [ps for ps in allowed_pool_sizes if ps <= pool_sizes[i - 1]]\n",
    "                    p = random.choice(allowed)\n",
    "                pool_sizes.append(p)\n",
    "\n",
    "            fcn_units = [random.randint(32, 256) for _ in range(fcn_layers)]\n",
    "\n",
    "            individual = DynamicNN(num_cnns=cnn_layers,\n",
    "                                   num_fcns=fcn_layers,\n",
    "                                   filters=filters,\n",
    "                                   kernel_sizes=kernel_sizes,\n",
    "                                   strides=strides,\n",
    "                                   pool_sizes=pool_sizes,\n",
    "                                   fcn_units=fcn_units,\n",
    "                                   activation_index=activation_index,\n",
    "                                   lr=lr).to(self.device)\n",
    "            self.population.append(individual)\n",
    "\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        child_cnn_layers = random.choice([parent1.num_cnns, parent2.num_cnns])\n",
    "        child_fcn_layers = random.choice([parent1.num_fcns, parent2.num_fcns])\n",
    "        child_activation_index = random.choice([parent1.activation_index, parent2.activation_index])\n",
    "        child_lr = random.choice([parent1.lr, parent2.lr])\n",
    "\n",
    "        def choose_param(list1, list2, idx):\n",
    "            if idx < len(list1) and idx < len(list2):\n",
    "                return random.choice([list1[idx], list2[idx]])\n",
    "            elif idx < len(list1):\n",
    "                return list1[idx]\n",
    "            elif idx < len(list2):\n",
    "                return list2[idx]\n",
    "            else:\n",
    "                return None  \n",
    "\n",
    "        child_filters = []\n",
    "        child_kernel_sizes = []\n",
    "        child_strides = []\n",
    "        child_pool_sizes = []\n",
    "        for i in range(child_cnn_layers):\n",
    "            filt = choose_param(parent1.filters, parent2.filters, i)\n",
    "            kernel = choose_param(parent1.kernel_sizes, parent2.kernel_sizes, i)\n",
    "            stride = choose_param(parent1.strides, parent2.strides, i)\n",
    "            pool = choose_param(parent1.pool_sizes, parent2.pool_sizes, i)\n",
    "            child_filters.append(filt)\n",
    "            child_kernel_sizes.append(kernel)\n",
    "            child_strides.append(stride)\n",
    "            child_pool_sizes.append(pool)\n",
    "\n",
    "        for i in range(1, child_cnn_layers):\n",
    "            if child_filters[i] > child_filters[i - 1]:\n",
    "                child_filters[i] = child_filters[i - 1]\n",
    "            if child_kernel_sizes[i] > child_kernel_sizes[i - 1]:\n",
    "                child_kernel_sizes[i] = child_kernel_sizes[i - 1]\n",
    "            if child_pool_sizes[i] > child_pool_sizes[i - 1]:\n",
    "                child_pool_sizes[i] = child_pool_sizes[i - 1]\n",
    "\n",
    "        child_fcn_units = []\n",
    "        for i in range(child_fcn_layers):\n",
    "            unit = choose_param(parent1.fcn_units, parent2.fcn_units, i)\n",
    "            if unit is None:\n",
    "                unit = random.randint(32, 256)\n",
    "            child_fcn_units.append(unit)\n",
    "\n",
    "        child = DynamicNN(num_cnns=child_cnn_layers,\n",
    "                          num_fcns=child_fcn_layers,\n",
    "                          filters=child_filters,\n",
    "                          kernel_sizes=child_kernel_sizes,\n",
    "                          strides=child_strides,\n",
    "                          pool_sizes=child_pool_sizes,\n",
    "                          fcn_units=child_fcn_units,\n",
    "                          activation_index=child_activation_index,\n",
    "                          lr=child_lr).to(self.device)\n",
    "        return child\n",
    "\n",
    "\n",
    "    def mutate(self, individual):\n",
    "        mutated = False\n",
    "\n",
    "        lr_choices = self.lr_choices\n",
    "        possible_filters = [16, 32, 64, 128]\n",
    "        allowed_kernel_sizes = [3, 5, 7]\n",
    "        allowed_pool_sizes = [2, 3, 4]\n",
    "\n",
    "        if random.random() < self.mutation_rate:\n",
    "            individual.num_cnns = random.randint(1, 4)\n",
    "            mutated = True\n",
    "        if random.random() < self.mutation_rate:\n",
    "            individual.num_fcns = random.randint(1, 4)\n",
    "            mutated = True\n",
    "        if random.random() < self.mutation_rate:\n",
    "            individual.activation_index = random.randint(0, len(self.activation_functions) - 1)\n",
    "            mutated = True\n",
    "        if random.random() < self.mutation_rate:\n",
    "            individual.lr = random.choice(lr_choices)\n",
    "            mutated = True\n",
    "\n",
    "        current_cnn_layers = individual.num_cnns\n",
    "        while len(individual.filters) < current_cnn_layers:\n",
    "            if len(individual.filters) == 0:\n",
    "                individual.filters.append(random.choice(possible_filters))\n",
    "            else:\n",
    "                allowed = [f for f in possible_filters if f <= individual.filters[-1]]\n",
    "                individual.filters.append(random.choice(allowed))\n",
    "        while len(individual.kernel_sizes) < current_cnn_layers:\n",
    "            if len(individual.kernel_sizes) == 0:\n",
    "                individual.kernel_sizes.append(random.choice(allowed_kernel_sizes))\n",
    "            else:\n",
    "                allowed = [k for k in allowed_kernel_sizes if k <= individual.kernel_sizes[-1]]\n",
    "                individual.kernel_sizes.append(random.choice(allowed))\n",
    "        while len(individual.strides) < current_cnn_layers:\n",
    "            individual.strides.append(random.randint(1, 2))\n",
    "        while len(individual.pool_sizes) < current_cnn_layers:\n",
    "            if len(individual.pool_sizes) == 0:\n",
    "                individual.pool_sizes.append(random.choice(allowed_pool_sizes))\n",
    "            else:\n",
    "                allowed = [p for p in allowed_pool_sizes if p <= individual.pool_sizes[-1]]\n",
    "                individual.pool_sizes.append(random.choice(allowed))\n",
    "\n",
    "        for i in range(current_cnn_layers):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                if i == 0:\n",
    "                    individual.filters[i] = random.choice(possible_filters)\n",
    "                else:\n",
    "                    allowed = [f for f in possible_filters if f <= individual.filters[i - 1]]\n",
    "                    individual.filters[i] = random.choice(allowed)\n",
    "                mutated = True\n",
    "            if random.random() < self.mutation_rate:\n",
    "                if i == 0:\n",
    "                    individual.kernel_sizes[i] = random.choice(allowed_kernel_sizes)\n",
    "                else:\n",
    "                    allowed = [k for k in allowed_kernel_sizes if k <= individual.kernel_sizes[i - 1]]\n",
    "                    individual.kernel_sizes[i] = random.choice(allowed)\n",
    "                mutated = True\n",
    "            if random.random() < self.mutation_rate:\n",
    "                individual.strides[i] = random.randint(1, 2)\n",
    "                mutated = True\n",
    "            if random.random() < self.mutation_rate:\n",
    "                if i == 0:\n",
    "                    individual.pool_sizes[i] = random.choice(allowed_pool_sizes)\n",
    "                else:\n",
    "                    allowed = [p for p in allowed_pool_sizes if p <= individual.pool_sizes[i - 1]]\n",
    "                    individual.pool_sizes[i] = random.choice(allowed)\n",
    "                mutated = True\n",
    "\n",
    "        current_fcn_layers = individual.num_fcns\n",
    "        while len(individual.fcn_units) < current_fcn_layers:\n",
    "            individual.fcn_units.append(random.randint(32, 256))\n",
    "        for i in range(current_fcn_layers):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                individual.fcn_units[i] = random.randint(32, 256)\n",
    "                mutated = True\n",
    "\n",
    "        if mutated:\n",
    "            new_individual = DynamicNN(num_cnns=individual.num_cnns,\n",
    "                                       num_fcns=individual.num_fcns,\n",
    "                                       filters=individual.filters,\n",
    "                                       kernel_sizes=individual.kernel_sizes,\n",
    "                                       strides=individual.strides,\n",
    "                                       pool_sizes=individual.pool_sizes,\n",
    "                                       fcn_units=individual.fcn_units,\n",
    "                                       activation_index=individual.activation_index,\n",
    "                                       lr=individual.lr).to(self.device)\n",
    "            individual = new_individual\n",
    "\n",
    "        return individual\n",
    "\n",
    "    def train_model(self, model):\n",
    "        optimizer = optim.Adam(model.parameters(), lr=model.lr)\n",
    "        best_val_accuracy = 0.0\n",
    "        patience = 2  \n",
    "        no_improvement = 0\n",
    "\n",
    "        train_loss_list = []\n",
    "        val_accuracy_list = []\n",
    "\n",
    "        print(f\"-----Training model-----\")\n",
    "        for epoch in range(self.epochs_per_model):\n",
    "            print(f\"Epoch {epoch + 1}: ...\")\n",
    "            model.train()\n",
    "            epoch_losses = []\n",
    "            for inputs, labels in self.train_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = self.criterion(torch.log(outputs), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_losses.append(loss.item())\n",
    "\n",
    "            avg_train_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else 0.0\n",
    "            train_loss_list.append(avg_train_loss)\n",
    "\n",
    "            model.eval()\n",
    "            val_correct, val_total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in self.val_loader:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            val_accuracy = val_correct / val_total if val_total > 0 else 0\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "            print(f\"Train Loss = {avg_train_loss:.4f}, Validation Accuracy = {val_accuracy:.4f}\")\n",
    "\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                no_improvement = 0\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "\n",
    "            if no_improvement >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        model.eval()\n",
    "        test_correct, test_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = test_correct / test_total if test_total > 0 else 0\n",
    "        print(f\"Final Test Accuracy = {test_accuracy:.4f}\")\n",
    "\n",
    "        return {\n",
    "            'train_losses': train_loss_list,\n",
    "            'val_accuracies': val_accuracy_list,\n",
    "            'test_accuracy': test_accuracy\n",
    "        }\n",
    "\n",
    "\n",
    "    def calculate_fitness(self, model):\n",
    "        try:\n",
    "            train_info = self.train_model(model)\n",
    "\n",
    "            last_train_loss = train_info['train_losses'][-1] if train_info['train_losses'] else float('inf')\n",
    "            last_val_accuracy = train_info['val_accuracies'][-1] if train_info['val_accuracies'] else 0.0\n",
    "            test_accuracy = train_info['test_accuracy']\n",
    "\n",
    "            fitness = (last_val_accuracy + test_accuracy) / 2.0\n",
    "\n",
    "            print(f\"Last epoch metrics - Train Loss: {last_train_loss:.4f}, Val Accuracy: {last_val_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "            print(f\"Calculated Fitness = {fitness:.4f}\")\n",
    "\n",
    "            return fitness\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError encountered during fitness evaluation: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "\n",
    "    def save_population_metrics_history(self, population_metrics_history):\n",
    "        history_dir = \"result/history\"\n",
    "        os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(history_dir, \"population_metrics_history.json\")\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(population_metrics_history, f, indent=4)\n",
    "\n",
    "        print(f\"Population metrics history saved to: {file_path}\")\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        if not (self.train_loader and self.val_loader and self.test_loader and self.criterion):\n",
    "            raise ValueError(\"Data loaders and criterion must be provided in the constructor.\")\n",
    "\n",
    "        best_model_dir = \"result/best_model\"\n",
    "        os.makedirs(best_model_dir, exist_ok=True)\n",
    "\n",
    "        self.initialize_population(num_cnn_layers_range=(1, 4), num_fcn_layers_range=(1, 4))\n",
    "        population_metrics_history = []\n",
    "        previous_best_child = None\n",
    "        previous_best_fitness = 0.0\n",
    "        generation_without_change = 0\n",
    "        best_child = None\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            print(f\"\\nGeneration {generation + 1}/{self.generations}\")\n",
    "            generation_metrics = [] \n",
    "            fitness_scores = []\n",
    "\n",
    "            for individual in self.population:\n",
    "                try:\n",
    "                    train_info = self.train_model(individual)\n",
    "                    last_val_accuracy = train_info['val_accuracies'][-1] if train_info['val_accuracies'] else 0.0\n",
    "                    test_accuracy = train_info['test_accuracy']\n",
    "                    fitness = (last_val_accuracy + test_accuracy) / 2.0\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"RuntimeError encountered: {e}\")\n",
    "                    train_info = {'train_losses': [], 'val_accuracies': [], 'test_accuracy': 0.0}\n",
    "                    fitness = 0.0\n",
    "\n",
    "                generation_metrics.append({\n",
    "                    'train_losses': train_info['train_losses'],\n",
    "                    'val_accuracies': train_info['val_accuracies'],\n",
    "                    'test_accuracy': train_info['test_accuracy'],\n",
    "                    'fitness': fitness\n",
    "                })\n",
    "                fitness_scores.append(fitness)\n",
    "\n",
    "            population_metrics_history.append(generation_metrics)\n",
    "\n",
    "            sorted_indices = sorted(range(len(fitness_scores)), key=lambda k: fitness_scores[k], reverse=True)\n",
    "            best_index = sorted_indices[0]\n",
    "            best_child = self.population[best_index]\n",
    "            best_fitness = fitness_scores[best_index]\n",
    "            print(f\"Best fitness in generation {generation + 1}: {best_fitness:.4f}\")\n",
    "\n",
    "            filename = os.path.join(best_model_dir, f\"generation_{generation + 1:02d}.pth\")\n",
    "            torch.save(best_child.state_dict(), filename)\n",
    "            print(f\"Saved best model for generation {generation + 1} as {filename}\")\n",
    "\n",
    "            num_selected = self.population_size // 2\n",
    "            selected_individuals = [self.population[i] for i in sorted_indices[:num_selected]]\n",
    "\n",
    "            new_population = selected_individuals.copy()\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected_individuals, 2)\n",
    "                child = self.crossover(parent1, parent2)\n",
    "                child = self.mutate(child)\n",
    "                new_population.append(child)\n",
    "            self.population = new_population\n",
    "\n",
    "            if previous_best_child is not None:\n",
    "                improvement = best_fitness - previous_best_fitness\n",
    "                if improvement < 0.005 * previous_best_fitness:\n",
    "                    generation_without_change += 1\n",
    "                else:\n",
    "                    generation_without_change = 0\n",
    "\n",
    "            if best_fitness >= 0.9999:\n",
    "                print(\"Achieved nearly perfect fitness. Early stopping (potential overfitting).\")\n",
    "                torch.save(best_child.state_dict(), os.path.join(best_model_dir, f\"generation_{generation + 1:02d}_overfitting.pth\"))\n",
    "                if previous_best_child:\n",
    "                    torch.save(previous_best_child.state_dict(), os.path.join(best_model_dir, f\"generation_{generation + 1:02d}_overfitting_prev.pth\"))\n",
    "                break\n",
    "\n",
    "            if generation_without_change >= 10:\n",
    "                print(\"No significant improvement in recent generations. Early stopping.\")\n",
    "                torch.save(best_child.state_dict(), os.path.join(best_model_dir, f\"generation_{generation + 1:02d}_no_improvement.pth\"))\n",
    "                break\n",
    "\n",
    "            previous_best_child = best_child\n",
    "            previous_best_fitness = best_fitness\n",
    "\n",
    "        else:\n",
    "            print(\"Finished all generations.\")\n",
    "            torch.save(best_child.state_dict(), os.path.join(best_model_dir, f\"generation_{self.generations:02d}_final.pth\"))\n",
    "\n",
    "        self.save_population_metrics_history(population_metrics_history)\n",
    "\n",
    "        return population_metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cV_-29p3z1Mm",
    "outputId": "05f0e4ee-ffa9-4e81-b645-d6a65a4f8389"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "data_dir = \"dataset/AfterPreprocess\"\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "loader_instance = Loader(data_dir=data_dir, batch_size=batch_size, validation_split=validation_split)\n",
    "train_loader, val_loader, test_loader = loader_instance.get_dataloader()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "ga_optimizer = GAOptimizer(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion\n",
    ")\n",
    "\n",
    "population_metrics_history = ga_optimizer.run()\n",
    "\n",
    "print(\"\\nPopulation Metrics History:\")\n",
    "for gen_index, gen_metrics in enumerate(population_metrics_history, start=1):\n",
    "    print(f\"\\nGeneration {gen_index}:\")\n",
    "    for ind_index, metric in enumerate(gen_metrics, start=1):\n",
    "        print(f\"  Individual {ind_index}:\")\n",
    "        print(f\"    Fitness: {metric['fitness']:.4f}\")\n",
    "        print(f\"    Final Test Accuracy: {metric['test_accuracy']:.4f}\")\n",
    "        print(f\"    Training Losses per Epoch: {metric['train_losses']}\")\n",
    "        print(f\"    Validation Accuracies per Epoch: {metric['val_accuracies']}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNQCc6nvT3Z+OBKjC19MNEa",
   "collapsed_sections": [
    "P0pEq30ymW0O"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
